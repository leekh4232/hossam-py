# -*- coding: utf-8 -*-
# -------------------------------------------------------------
import requests
import json
import tempfile
import zipfile
import shutil
from pathlib import Path
from typing import TYPE_CHECKING
from importlib.metadata import distributions
import pandas as pd
import numpy as np
from pandas import DataFrame, DatetimeIndex, read_csv, read_excel
from scipy.stats import normaltest
from tabulate import tabulate
from os.path import join, exists
from io import BytesIO
from pandas import DataFrame, read_csv, read_excel
from typing import Optional, Tuple, Any

BASE_URL = "https://data.hossam.kr"

# -------------------------------------------------------------
def __get_df(path: str, index_col=None) -> DataFrame:
    p = path.rfind(".")
    exec = path[p+1:].lower()

    # íŒŒì¼ í™•ì¥ìê°€ ì••ì¶•íŒŒì¼ì¸ ê²½ìš° ë¡œì»¬ì— íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í›„ ì••ì¶• í•´ì œ
    if exec == "zip":
        tmp_dir = Path(tempfile.mkdtemp())
        zip_path = tmp_dir / "data.zip"

        # ì›ê²© URLì¸ ê²½ìš° íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        if path.lower().startswith(('http://', 'https://')):
            path = path.replace("\\", "/")
            with requests.Session() as session:
                r = session.get(path)

                if r.status_code != 200:
                    raise Exception(f"HTTP {r.status_code} Error - {r.reason} > {path}")

                with open(zip_path, "wb") as f:
                    f.write(r.content)
        else:
            zip_path = Path(path)

        # ì••ì¶• í•´ì œ
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(tmp_dir)

        # ì••ì¶• í•´ì œëœ íŒŒì¼ ì¤‘ ì²« ë²ˆì§¸ íŒŒì¼ì„ ë°ì´í„°ë¡œ ë¡œë“œ
        extracted_files = list(tmp_dir.glob('*'))
        if not extracted_files:
            raise FileNotFoundError("ì••ì¶• íŒŒì¼ ë‚´ì— ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        path = str(extracted_files[0])
        p = path.rfind(".")
        exec = path[p+1:].lower()

        # ìƒì„±ëœ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
        shutil.rmtree(tmp_dir)


    if exec == 'xlsx':
        # If path is a remote URL, fetch the file once and reuse the bytes
        if path.lower().startswith(('http://', 'https://')):
            path = path.replace("\\", "/")
            with requests.Session() as session:
                r = session.get(path)

                if r.status_code != 200:
                    raise Exception(f"HTTP {r.status_code} Error - {r.reason} > {path}")

                data_bytes = r.content

            # Use separate BytesIO objects for each read to avoid pointer/stream issues
            df = read_excel(BytesIO(data_bytes), index_col=index_col)

            try:
                info = read_excel(BytesIO(data_bytes), sheet_name='metadata', index_col=0)
                #print("\033[94m[metadata]\033[0m")
                print()
                pretty_table(info)
                print()
            except Exception:
                #print(f"\033[91m[!] Cannot read metadata\033[0m")
                pass
        else:
            df = read_excel(path, index_col=index_col)

            try:
                info = read_excel(path, sheet_name='metadata', index_col=0)
                #print("\033[94m[metadata]\033[0m")
                print()
                pretty_table(info)
                print()
            except:
                #print(f"\033[91m[!] Cannot read metadata\033[0m")
                pass
    else:
        df = read_csv(path, index_col=index_col)

    return df

# -------------------------------------------------------------
def __get_data_url(key: str, local: str | None = None) -> Tuple[str, Any, Any]:
    global BASE_URL

    path = None

    if not local:
        data_path = join(BASE_URL, "metadata.json").replace("\\", "/")

        with requests.Session() as session:
            r = session.get(data_path)

            if r.status_code != 200:
                raise Exception("[%d Error] %s" % (r.status_code, r.reason))

        my_dict = r.json()
        info = my_dict.get(key.lower())

        if not info:
            raise FileNotFoundError("%sëŠ” ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì— ëŒ€í•œ ìš”ì²­ì…ë‹ˆë‹¤." % key)

        path = join(BASE_URL, info['url'])
    else:
        data_path = join(local, "metadata.json")

        if not exists(data_path):
            raise FileNotFoundError("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì— ëŒ€í•œ ìš”ì²­ì…ë‹ˆë‹¤.")

        with open(data_path, "r", encoding="utf-8") as f:
            my_dict = json.loads(f.read())

        info = my_dict.get(key.lower())
        path = join(local, info['url'])

    return path, info.get('desc'), info.get('index')

# -------------------------------------------------------------
def load_info(search: str | None = None, local: str | None = None) -> DataFrame:
    """ë©”íƒ€ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ë¡œë“œí•œë‹¤.

    Args:
        search (str, optional): ì´ë¦„ í•„í„° ë¬¸ìì—´. í¬í•¨í•˜ëŠ” í•­ëª©ë§Œ ë°˜í™˜.
        local (str, optional): ë¡œì»¬ ë©”íƒ€ë°ì´í„° ê²½ë¡œ. Noneì´ë©´ ì›ê²©(BASE_URL) ì‚¬ìš©.

    Returns:
        DataFrame: name, chapter, desc, url ì»¬ëŸ¼ì„ ê°–ëŠ” í…Œì´ë¸”

    Examples:
        ```python
        from hossam import *
        info = load_info()
        list(info.columns) #['name', 'chapter', 'desc', 'url']
        ```
    """
    global BASE_URL

    path = None

    if not local:
        data_path = join(BASE_URL, "metadata.json").replace("\\", "/")

        with requests.Session() as session:
            r = session.get(data_path)

            if r.status_code != 200:
                raise Exception("[%d Error] %s ::: %s" % (r.status_code, r.reason, data_path))

        my_dict = r.json()
    else:
        data_path = join(local, "metadata.json")

        if not exists(data_path):
            raise FileNotFoundError("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì— ëŒ€í•œ ìš”ì²­ì…ë‹ˆë‹¤.")

        with open(data_path, "r", encoding="utf-8") as f:
            my_dict = json.loads(f.read())

    my_data = []
    for key in my_dict:
        if 'index' in my_dict[key]:
            del my_dict[key]['index']

        my_dict[key]['url'] = "%s/%s" % (BASE_URL, my_dict[key]['url'])
        my_dict[key]['name'] = key

        if 'chapter' in my_dict[key]:
            my_dict[key]['chapter'] = ", ".join(my_dict[key]['chapter'])
        else:
            my_dict[key]['chapter'] = 'ê³µí†µ'

        my_data.append(my_dict[key])

    my_df = DataFrame(my_data)
    my_df2 = my_df.reindex(columns=['name', 'chapter', 'desc', 'url'])

    if search:
        my_df2 = my_df2[my_df2['name'].str.contains(search.lower())]

    return my_df2

# -------------------------------------------------------------
def _load_data_remote(key: str, local: str | None = None) -> Optional[DataFrame]:
    """í‚¤ë¡œ ì§€ì •ëœ ë°ì´í„°ì…‹ì„ ë¡œë“œí•œë‹¤.

    Args:
        key (str): ë©”íƒ€ë°ì´í„°ì— ì •ì˜ëœ ë°ì´í„° ì‹ë³„ì(íŒŒì¼ëª… ë˜ëŠ” ë³„ì¹­)
        local (str, optional): ë¡œì»¬ ë©”íƒ€ë°ì´í„° ê²½ë¡œ. Noneì´ë©´ ì›ê²©(BASE_URL) ì‚¬ìš©.

    Returns:
        DataFrame | None: ì„±ê³µ ì‹œ ë°ì´í„°í”„ë ˆì„, ì‹¤íŒ¨ ì‹œ None

    Examples:
        ```python
        from hossam import *
        df = load_data('AD_SALES')  # ë©”íƒ€ë°ì´í„°ì— í•´ë‹¹ í‚¤ê°€ ìˆì–´ì•¼ í•¨
        ```
    """
    index = None
    try:
        url, desc, index = __get_data_url(key, local=local)
    except Exception as e:
        try:
            print(f"\033[91m{str(e)}\033[0m")
        except Exception:
            print(e)
        return

    #print("\033[94m[data]\033[0m", url.replace("\\", "/"))
    #print("\033[94m[desc]\033[0m", desc)
    print(f"\033[94m{desc}\033[0m")

    df = None

    try:
        df = __get_df(url, index_col=index)
    except Exception as e:
        try:
            print(f"\033[91m{str(e)}\033[0m")
        except Exception:
            print(e)
        return


    return df

# ===================================================================
# ì„¤ì¹˜ëœ íŒŒì´ì¬ íŒ¨í‚¤ì§€ ëª©ë¡ ë°˜í™˜
# ===================================================================
def my_packages():
    """
    í˜„ì¬ íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ì— ì„¤ì¹˜ëœ ëª¨ë“  íŒ¨í‚¤ì§€ì˜ ì´ë¦„ê³¼ ë²„ì „ì„
    íŒ¨í‚¤ì§€ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ pandas DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    Returns:
        pd.DataFrame: columns=['name', 'version']
    """
    pkgs = []
    for dist in distributions():
        name = dist.metadata['Name'] if 'Name' in dist.metadata else dist.name
        version = dist.version
        summary = dist.metadata.get('Summary', '')
        pkgs.append((name, version, summary))
    pkgs = sorted(pkgs, key=lambda x: x[0].lower())
    return pd.DataFrame(pkgs, columns=['name', 'version', 'summary'])

# ===================================================================
# ì •ê·œë¶„í¬ ë°ì´í„° ìƒì„±
# ===================================================================
def make_normalize_values(
    mean: float, std: float, size: int = 100, round: int = 2
) -> np.ndarray:
    """ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•œë‹¤.

    Args:
        mean (float): í‰ê· 
        std (float): í‘œì¤€í¸ì°¨
        size (int, optional): ë°ì´í„° í¬ê¸°. Defaults to 100.
        round (int, optional): ì†Œìˆ˜ì  ë°˜ì˜¬ë¦¼ ìë¦¬ìˆ˜. Defaults to 2.

    Returns:
        np.ndarray: ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë°ì´í„°

    Examples:
        ```python
        from hossam import *
        x = hs.util.make_normalize_values(mean=0.0, std=1.0, size=100)
        ```
    """
    p = 0.0
    x: np.ndarray = np.array([])
    attempts = 0
    max_attempts = 100  # ë¬´í•œ ë£¨í”„ ë°©ì§€
    while p < 0.05 and attempts < max_attempts:
        x = np.random.normal(mean, std, size).round(round)
        _, p = normaltest(x)
        attempts += 1

    return x


# ===================================================================
# ì •ê·œë¶„í¬ ë°ì´í„°í”„ë ˆì„ ìƒì„±
# ===================================================================
def make_normalize_data(
    means: list | None = None,
    stds: list | None = None,
    sizes: list | None = None,
    rounds: int = 2,
) -> DataFrame:
    """ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•œë‹¤.

    Args:
        means (list, optional): í‰ê·  ëª©ë¡. Defaults to [0, 0, 0].
        stds (list, optional): í‘œì¤€í¸ì°¨ ëª©ë¡. Defaults to [1, 1, 1].
        sizes (list, optional): ë°ì´í„° í¬ê¸° ëª©ë¡. Defaults to [100, 100, 100].
        rounds (int, optional): ë°˜ì˜¬ë¦¼ ìë¦¬ìˆ˜. Defaults to 2.

    Returns:
        DataFrame: ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë°ì´í„°í”„ë ˆì„
    """
    means = means if means is not None else [0, 0, 0]
    stds = stds if stds is not None else [1, 1, 1]
    sizes = sizes if sizes is not None else [100, 100, 100]

    if not (len(means) == len(stds) == len(sizes)):
        raise ValueError("means, stds, sizes ê¸¸ì´ëŠ” ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.")

    data = {}
    for i in range(len(means)):
        data[f"X{i+1}"] = make_normalize_values(
            means[i], stds[i], sizes[i], rounds
        )

    return DataFrame(data)


# ===================================================================
# DataFrameì„ ì´ì˜ê²Œ ì¶œë ¥
# ===================================================================
def pretty_table(data: DataFrame, tablefmt="simple", headers: str = "keys") -> None:
    """`tabulate`ë¥¼ ì‚¬ìš©í•´ DataFrameì„ ë‹¨ìˆœ í‘œ í˜•íƒœë¡œ ì¶œë ¥í•œë‹¤.

    Args:
        data (DataFrame): ì¶œë ¥í•  ë°ì´í„°í”„ë ˆì„
        tablefmt (str, optional): `tabulate` í…Œì´ë¸” í¬ë§·. Defaults to "simple".
        headers (str | list, optional): í—¤ë” ì§€ì • ë°©ì‹. Defaults to "keys".

    Returns:
        None

    Examples:
        ```python
        from hossam import *
        from pandas import DataFrame
        hs_util.pretty_table(DataFrame({"a":[1,2],"b":[3,4]}))
        ```
    """

    tabulate.WIDE_CHARS_MODE = False # type: ignore
    print(
        tabulate(data, headers=headers, tablefmt=tablefmt, showindex=True, numalign="right") # type: ignore
    )


# ===================================================================
# ë°ì´í„° í”„ë ˆì„ì„ í†µí•´ í•„ìš”í•œ ì´ˆê¸° ì‘ì—…ì„ ìˆ˜í–‰
# ===================================================================
def __data_info(
    origin: DataFrame,
    index_col: str | None = None,
    timeindex: bool = False,
    info: bool = True,
    categories: list | None = None,
) -> DataFrame:
    """ë°ì´í„° í”„ë ˆì„ì„ í†µí•´ í•„ìš”í•œ ì´ˆê¸° ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.

    Args:
        origin (DataFrame): ì›ë³¸ ë°ì´í„° í”„ë ˆì„
        index_col (str, optional): ì¸ë±ìŠ¤ í•„ë“œì˜ ì´ë¦„. Defaults to None.
        timeindex (bool, optional): Trueì¼ ê²½ìš° ì¸ë±ìŠ¤ë¥¼ ì‹œê³„ì—´ë¡œ ì„¤ì •. Defaults to False.
        info (bool, optional): Trueì¼ ê²½ìš° ì •ë³´ ì¶œë ¥. Defaults to True.
        categories (list, optional): ì¹´í…Œê³ ë¦¬ë¡œ ì§€ì •í•  í•„ë“œ ëª©ë¡. Defaults to None.

    Returns:
        DataFrame: ë°ì´í„°í”„ë ˆì„ ê°ì²´
    """

    data = origin.copy()

    if index_col is not None and index_col in data.columns:
        data.set_index(index_col, inplace=True)

    if timeindex:
        data.index = DatetimeIndex(data.index)

    if categories:
        from .hs_prep import set_category  # type: ignore
        data = set_category(data, *categories)

    if info:
        print("\nâœ… í…Œì´ë¸” ì •ë³´")
        pretty_table(data.info(), tablefmt="pretty") # type: ignore

        print("\nâœ… ìƒìœ„ 5ê°œ í–‰")
        pretty_table(data.head(), tablefmt="pretty")

        print("\nâœ… í•˜ìœ„ 5ê°œ í–‰")
        pretty_table(data.tail(), tablefmt="pretty")

        print("\nğŸ“Š ê¸°ìˆ í†µê³„")
        desc = data.describe().T
        desc["nan"] = data.isnull().sum()
        pretty_table(desc, tablefmt="pretty")

        # ì „ë‹¬ëœ í•„ë“œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ë°˜ë³µ
        if categories:
            print("\nğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ì •ë³´")
            for c in categories:
                d = DataFrame({"count": data[c].value_counts()})
                d.index.name = c
                pretty_table(d, tablefmt="pretty")

    return data


# ===================================================================
# ë°ì´í„° ë¡œë“œ
# ===================================================================
def load_data(key: str,
                index_col: str | None = None,
                timeindex: bool = False,
                info: bool = True,
                categories: list | None = None,
                local: str | None = None) -> DataFrame:
    """ë°ì´í„° í‚¤ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë¡œë“œí•œ ë’¤ ê¸°ë³¸ ì „ì²˜ë¦¬/ì¶œë ¥ì„ ìˆ˜í–‰í•œë‹¤.

    Args:
        key (str): ë°ì´í„° í‚¤ (metadata.jsonì— ì •ì˜ëœ ë°ì´í„° ì‹ë³„ì)
        index_col (str, optional): ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•  ì»¬ëŸ¼ëª…. Defaults to None.
        timeindex (bool, optional): Trueì¼ ê²½ìš° ì¸ë±ìŠ¤ë¥¼ ì‹œê³„ì—´(DatetimeIndex)ë¡œ ì„¤ì •í•œë‹¤. Defaults to False.
        info (bool, optional): Trueì¼ ê²½ìš° ë°ì´í„° ì •ë³´(head, tail, ê¸°ìˆ í†µê³„, ì¹´í…Œê³ ë¦¬ ì •ë³´)ë¥¼ ì¶œë ¥í•œë‹¤. Defaults to True.
        categories (list, optional): ì¹´í…Œê³ ë¦¬ dtypeìœ¼ë¡œ ì„¤ì •í•  ì»¬ëŸ¼ëª… ëª©ë¡. Defaults to None.
        local (str, optional): ì›ê²© ë°ì´í„° ëŒ€ì‹  ë¡œì»¬ ë©”íƒ€ë°ì´í„° ê²½ë¡œë¥¼ ì‚¬ìš©í•œë‹¤. Defaults to None.

    Returns:
        DataFrame: ì „ì²˜ë¦¬(ì¸ë±ìŠ¤ ì„¤ì •, ì¹´í…Œê³ ë¦¬ ë³€í™˜)ê°€ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„

    Examples:
        ```python
        from hossam import *
        df = hs_util.load_data("AD_SALES", index_col=None, timeindex=False, info=False)
        ```
    """

    k = key.lower()

    origin = None

    if k.endswith(".xlsx"):
        origin = read_excel(key)
    elif k.endswith(".csv"):
        origin = read_csv(key)
    else:
        origin = _load_data_remote(key, local) # type: ignore

    if origin is None:
        raise RuntimeError("Data loading failed: origin is None")

    return __data_info(origin, index_col, timeindex, info, categories)
